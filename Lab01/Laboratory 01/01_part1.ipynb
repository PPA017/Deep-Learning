{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeG__6p8FZHC"
      },
      "source": [
        "# PyTorch Workflow\n",
        "\n",
        "Let's explore a an example PyTorch end-to-end workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_n_NlLzFwEN"
      },
      "outputs": [],
      "source": [
        "what_were_covering = {1: \"data (prepare and load)\",\n",
        "                      2: \"build model\",\n",
        "                      3: \"fitting the model to data (training)\",\n",
        "                      4: \"making predictions and evaluting a model (inference)\",\n",
        "                      5: \"saving and loading a model\",\n",
        "                      6: \"putting it all together\"}\n",
        "\n",
        "what_were_covering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJN3I__OGWOe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2To7sJG02NX5"
      },
      "source": [
        "Create device-agnostic code.\n",
        "\n",
        "This means if we've got access to a GPU, our code will use it (for potentially faster computing).\n",
        "\n",
        "If no GPU is available, the code will default to using CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr47KwzH2ME7"
      },
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg1IBDfEG207"
      },
      "source": [
        "## 1. Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything... in machine learning.\n",
        "\n",
        "* Excel speadsheet\n",
        "* Images of any kind\n",
        "* Videos (YouTube has lots of data...)\n",
        "* Audio like songs or podcasts\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into a numerical representation.\n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula.\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* **parameters**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hCumNpHHCTU"
      },
      "outputs": [],
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrPJV_XkJgRT"
      },
      "outputs": [],
      "source": [
        "len(X), len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GTAEnvLJlq6"
      },
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
        "\n",
        "Let's create a training and test set with our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpMm7mp_KtNH"
      },
      "outputs": [],
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgb1fH7FL0O8"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yWmPL7gMfPE"
      },
      "outputs": [],
      "source": [
        "plot_predictions();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z7q5QhLOv_q"
      },
      "source": [
        "## 2. Build model\n",
        "\n",
        "Our first PyTorch model!\n",
        "\n",
        "Because we're going to be building classes throughout the course, I'd recommend getting familiar with OOP in Python, to do so you can use the following resource from Real Python: https://realpython.com/python3-object-oriented-programming/\n",
        "\n",
        "What our model does:\n",
        "* Start with random values (weight & bias)\n",
        "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qirhP4VUkOky"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Create linear regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherhits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight\n",
        "                                            requires_grad=True, # <- can this parameter be updated via gradient descent?\n",
        "                                            dtype=torch.float))\n",
        "\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad=True,\n",
        "                                         dtype=torch.float))\n",
        "\n",
        "  # Forward method to define the computation in the model\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
        "    return self.weights * x + self.bias # this is the linear regression formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH_vD6ICnRUO"
      },
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
        "* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
        "* torch.optim - this where the optimizers in PyTorch live, they will help with gradient descent\n",
        "* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8fP6B0rYnN"
      },
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now we've created a model, let's see what's inside...\n",
        "\n",
        "So we can check our model parameters or what's inside our model using `.parameters()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0737rQGNtDxP"
      },
      "outputs": [],
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdzvifGftWYZ"
      },
      "outputs": [],
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs87RRo029TV"
      },
      "outputs": [],
      "source": [
        "# Set the model to use the target device\n",
        "model_0.to(device)\n",
        "next(model_0.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlAsG4S-uJO5"
      },
      "source": [
        "### Making prediction using `torch.inference_mode()`\n",
        "\n",
        "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
        "\n",
        "When we pass data through our model, it's going to run it through the `forward()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_nRrqGMwm0N"
      },
      "outputs": [],
      "source": [
        "y_preds = model_0(X_test)\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCASe_bouVKL"
      },
      "outputs": [],
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "\n",
        "# # You can also do something similar with torch.no_grad(), however, torch.inference_mode() is preferred\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVREWa_BvzI0"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "331WoqFewSnl"
      },
      "outputs": [],
      "source": [
        "plot_predictions(predictions=y_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC7cHOnqwWi8"
      },
      "source": [
        "## 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
        "\n",
        "Or in other words from a poor representation of the data to a better representation of the data.\n",
        "\n",
        "One way to measure how poor or how wrong your models predictions are is to use a loss function.\n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
        "\n",
        "Things we need to train:\n",
        "\n",
        "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
        "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias in our case) to improve the loss function - https://pytorch.org/docs/stable/optim.html#module-torch.optim\n",
        "  * Inside the optimizer you'll often have to set two parameters:\n",
        "    * `params` - the model parameters you'd like to optimize, for example `params=model_0.parameters()`\n",
        "    * `lr` (learning rate) - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small `lr` results in small changes, a large `lr` results in large changes)\n",
        "\n",
        "And specifically for PyTorch, we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR7Xy8FqQ1x1"
      },
      "outputs": [],
      "source": [
        "list(model_0.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhpnOr3vR5jI"
      },
      "outputs": [],
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), # we want to optimize the parameters present in our model\n",
        "                            lr=0.01) # lr = learning rate = possibly the most important hyperparameter you can set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR0wku4LUzr7"
      },
      "source": [
        "> **Q:** Which loss function and optimizer should I use?\n",
        ">\n",
        "> **A:** This will be problem specific. But with experience, you'll get an idea of what works and what doesn't with your particular problem set.\n",
        ">\n",
        "> For example, for a regression problem (like ours), a loss function of `nn.L1Loss()` and an optimizer like `torch.optim.SGD()` will suffice.\n",
        ">\n",
        "> But for a classification problem like classifying whether a photo is of a dog or a cat, you'll likely want to use a loss function of `nn.BCELoss()` (binary cross entropy loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffr8kYJTXwkD"
      },
      "source": [
        "### Building a training loop (and a testing loop) in PyTorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through the data and do...\n",
        "1. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
        "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss\n",
        "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV8WOxYPaTlP"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch is one loop through the data... (this is a hyperparameter because we've set it ourselves)\n",
        "epochs = 200\n",
        "\n",
        "# Put data on the target device (device agnostic code for data)\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "### Training\n",
        "# 0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model (calculate gradients of each parameter)\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode():\n",
        "  # with torch.no_grad(): # you may also see torch.no_grad() in older PyTorch code\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out what's happenin'\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6EZVQi1759Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.array(torch.tensor(loss_values).numpy()), torch.tensor(test_loss_values).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccr-GEYe7da1"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfl9oAt_09Fd"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_gboBMSl13p"
      },
      "outputs": [],
      "source": [
        "plot_predictions(predictions=y_preds);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y-u_rVC16XJ"
      },
      "outputs": [],
      "source": [
        "plot_predictions(predictions=y_preds_new);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXusQ2JP1_S1"
      },
      "source": [
        "## Saving a model in PyTorch\n",
        "\n",
        "There are three main methods you should about for saving and loading models in PyTorch.\n",
        "\n",
        "1. `torch.save()` - allows you save a PyTorch object in Python's pickle format\n",
        "2. `torch.load()` - allows you load a saved PyTorch object\n",
        "3. `torch.nn.Module.load_state_dict()` - this allows to load a model's saved state dictionary\n",
        "\n",
        "PyTorch save & load code tutorial + extra-curriculum - https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a0iaBiX5JAG"
      },
      "outputs": [],
      "source": [
        "# Saving our PyTorch model\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os6BGzXT54Xq"
      },
      "outputs": [],
      "source": [
        "!ls -l models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uib6vQMB7Ds1"
      },
      "source": [
        "## Loading a PyTorch model\n",
        "\n",
        "Since we saved our model's `state_dict()` rather the entire model, we'll create a new instance of our model class and load the saved `state_dict()` into that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U-uXVaC85PP"
      },
      "outputs": [],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTghUxOH89lz"
      },
      "outputs": [],
      "source": [
        "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_44x4te89OjW"
      },
      "outputs": [],
      "source": [
        "loaded_model_0.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxPDLIU09Q0i"
      },
      "outputs": [],
      "source": [
        "# Make some predictions with our loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BP9cufq99K-"
      },
      "outputs": [],
      "source": [
        "# Make some models preds\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSbACbvI94XX"
      },
      "outputs": [],
      "source": [
        "# Compare loaded model preds with original model preds\n",
        "y_preds == loaded_model_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh1HuUNmtxt_"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH7K56Dn3xcX"
      },
      "source": [
        "## 1. Create a straight line dataset using the linear regression formula (`weight * X + bias`).\n",
        "  * Set `weight=0.3` and `bias=0.9` there should be at least 100 datapoints total.\n",
        "  * Split the data into 80% training, 20% testing.\n",
        "  * Plot the training and testing data so it becomes visual.\n",
        "\n",
        "Your output of the below cell should look something like:\n",
        "```\n",
        "Number of X samples: 100\n",
        "Number of y samples: 100\n",
        "First 10 X & y samples:\n",
        "X: tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
        "        0.0900])\n",
        "y: tensor([0.9000, 0.9030, 0.9060, 0.9090, 0.9120, 0.9150, 0.9180, 0.9210, 0.9240,\n",
        "        0.9270])\n",
        "```\n",
        "\n",
        "Of course the numbers in `X` and `y` may be different but ideally they're created using the linear regression formula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YXdbK5C34GM"
      },
      "source": [
        "## 2. Build a PyTorch model by subclassing `nn.Module`.\n",
        "  * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
        "  * Implement the `forward()` method to compute the linear regression function you used to create the dataset in 1.\n",
        "  * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
        "  * **Note:** If you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW-nFpro39Js"
      },
      "source": [
        "## 3. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively.\n",
        "  * Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters from the model you created in 2.\n",
        "  * Write a training loop to perform the appropriate training steps for 300 epochs.\n",
        "  * The training loop should test the model on the test dataset every 20 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qskFL6FC4Jzf"
      },
      "source": [
        "## 4. Make predictions with the trained model on the test data.\n",
        "  * Visualize these predictions against the original training and testing data (**note:** you may need to make sure the predictions are *not* on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRgqwrvZ4Q3L"
      },
      "source": [
        "## 5. Save your trained model's `state_dict()` to file.\n",
        "  * Create a new instance of your model class you made in 2. and load in the `state_dict()` you just saved to it.\n",
        "  * Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
